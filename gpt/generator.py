# ğŸ“ gpt/generator.py (âœ… ë¬¸ì œ ì •ì œ í•„í„°ë§ + ëœë¤ ë°ì´í„°ì…‹ ì„ íƒ êµ¬ì¡° ì§€ì›)
import sys, os, random
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import OpenAI
from dotenv import load_dotenv
from tools.paths import (
    PROMPT_PATHS,
    NEW_QUESTIONS_PATH,
    ENV_PATH,
)

# ğŸ”§ ì§ì ‘ ê²½ë¡œ ì§€ì • (ACTIVE_DATASETS_PATH ë¯¸ì •ì˜ ì‹œ ì˜¤ë¥˜ ë°©ì§€)
ACTIVE_DATASETS_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "config", "active_dataset.txt")

# ğŸ” í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° Groq API ì„¤ì •
load_dotenv(dotenv_path=ENV_PATH)
client = OpenAI(
    api_key=os.getenv("GROQ_API_KEY"),
    base_url="https://api.groq.com/openai/v1"
)

# ğŸ“¥ í…œí”Œë¦¿ ë¡œë“œ í•¨ìˆ˜
def load_prompt_template(tool):
    path = PROMPT_PATHS[tool]
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

# âœ‚ï¸ GPT ì‘ë‹µ ì •ì œ í•¨ìˆ˜
def clean_gpt_response(text):
    lines = text.strip().split("\n")
    valid = [
        line.strip() for line in lines
        if line.count("|") >= 4 and line.strip()[0].isdigit() and any("ê°€" <= ch <= "í£" for ch in line)
    ]
    return "\n".join(valid)

# ğŸ² ëœë¤ ë°ì´í„°ì…‹ 1ê°œ ì„ íƒ í•¨ìˆ˜
def choose_random_dataset():
    with open(ACTIVE_DATASETS_PATH, "r", encoding="utf-8") as f:
        datasets = [line.strip() for line in f if line.strip()]
    selected = random.choice(datasets)
    print(f"ğŸ¯ ì´ë²ˆ ì‹¤í–‰ì— ì„ íƒëœ ë°ì´í„°ì…‹: {selected}")
    return selected

# ğŸ§  ë¬¸ì œ ìƒì„± í•¨ìˆ˜ (Groq ê¸°ë°˜)
def generate_questions(dataset, tool, model="llama3-8b-8192"):
    prompt = load_prompt_template(tool).format(dataset=dataset)

    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë°ì´í„° ë¶„ì„ ë¬¸ì œë¥¼ ë§Œë“œëŠ” AIì•¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=1000
    )

    raw_output = response.choices[0].message.content
    return clean_gpt_response(raw_output)

# ğŸ’¾ ì •ì œëœ ë¬¸ì œ ì €ì¥ í•¨ìˆ˜
def save_questions(text):
    filtered = clean_gpt_response(text)
    with open(NEW_QUESTIONS_PATH, "a", encoding="utf-8") as f:
        f.write(filtered.strip() + "\n")

# â–¶ï¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    dataset = choose_random_dataset()
    for tool in ["pds", "sql", "viz"]:
        result = generate_questions(dataset, tool)
        print(f"\nğŸ“˜ ìƒì„±ëœ ë¬¸ì œ ({tool}):")
        print(result)
        save_questions(result)

# âœ… run_all.pyì™€ ì—°ë™ ì‹œ: ë§¤ ì‹¤í–‰ë§ˆë‹¤ í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ë§Œ ë¬´ì‘ìœ„ ì„ íƒë˜ì–´ ë¬¸ì œ ìƒì„±ë¨
